{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setup Environment\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Project-MONAI/tutorials/blob/master/3d_registration/paired_lung_ct.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%pip install -q \"monai[nibabel, tqdm]\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%pip install -q matplotlib\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Copyright 2020 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.losses import DiceLoss, BendingEnergyLoss\n",
    "from monai.metrics import compute_meandice\n",
    "from monai.networks.blocks import Warp\n",
    "from monai.networks.nets import LocalNet\n",
    "from monai.transforms import LoadImaged, AddChanneld, ToTensord, Compose, ScaleIntensityRanged, RandAffined\n",
    "from monai.utils import set_determinism, first\n",
    "\n",
    "print_config()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup data directory\n",
    "\n",
    "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable.\n",
    "This allows you to save results and reuse downloads.\n",
    "If not specified a temporary directory will be used."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paired_ct_lung\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "resource = \"https://zenodo.org/record/3835682/files/training.zip\"\n",
    "\n",
    "compressed_file = os.path.join(root_dir, \"paired_ct_lung.zip\")\n",
    "data_dir = os.path.join(root_dir, \"paired_ct_lung\")\n",
    "if not os.path.exists(data_dir):\n",
    "    download_and_extract(resource, compressed_file, root_dir)\n",
    "    os.rename(os.path.join(root_dir, \"training\"), data_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set dataset path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "data_dicts = [\n",
    "    {\n",
    "        \"fixed_image\": os.path.join(data_dir, \"scans/case_%03d_insp.nii.gz\" % idx),\n",
    "        \"moving_image\": os.path.join(data_dir, \"scans/case_%03d_exp.nii.gz\" % idx),\n",
    "        \"fixed_label\": os.path.join(data_dir, \"lungMasks/case_%03d_insp.nii.gz\" % idx),\n",
    "        \"moving_label\": os.path.join(data_dir, \"lungMasks/case_%03d_exp.nii.gz\" % idx),\n",
    "    }\n",
    "    for idx in range(1, 21)\n",
    "]\n",
    "\n",
    "train_files, val_files = data_dicts[:18], data_dicts[18:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set deterministic training for reproducibility"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "set_determinism(seed=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup transforms for training and validation\n",
    "Here we use several transforms to augment the dataset:\n",
    "1. LoadImaged loads the lung CT images and labels from NIfTI format files.\n",
    "2. AddChanneld as the original data doesn't have channel dim, add 1 dim to construct \"channel first\" shape.\n",
    "5. ScaleIntensityRanged extracts intensity range [-57, 164] and scales to [0, 1].\n",
    "9. RandAffined efficiently performs rotate, scale, shear, translate, etc. together based on PyTorch affine transform.\n",
    "10. ToTensord converts the numpy array to PyTorch Tensor for further steps."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"fixed_image\", \"moving_image\", \"fixed_label\", \"moving_label\"]),\n",
    "        AddChanneld(keys=[\"fixed_image\", \"moving_image\", \"fixed_label\", \"moving_label\"]),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"fixed_image\", \"moving_image\"], a_min=-285, a_max=3770, b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        # random affine transforms\n",
    "        RandAffined(keys=[\"fixed_image\", \"moving_image\", \"fixed_label\", \"moving_label\"],\n",
    "                    mode=('bilinear', 'nearest', 'bilinear', 'nearest'),\n",
    "                    prob=1.0, spatial_size=(192, 192, 208),\n",
    "                    rotate_range=(0, 0, np.pi/15), scale_range=(0.1, 0.1, 0.1)),\n",
    "        ToTensord(keys=[\"fixed_image\", \"moving_image\", \"fixed_label\", \"moving_label\"]),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"fixed_image\", \"moving_image\", \"fixed_label\", \"moving_label\"]),\n",
    "        AddChanneld(keys=[\"fixed_image\", \"moving_image\", \"fixed_label\", \"moving_label\"]),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"fixed_image\", \"moving_image\"], a_min=-285, a_max=3770, b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        ToTensord(keys=[\"fixed_image\", \"moving_image\", \"fixed_label\", \"moving_label\"]),\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check transforms in DataLoader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "check_ds = Dataset(data=val_files, transform=train_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "check_data = first(check_loader)\n",
    "fixed_image, fixed_label = (check_data[\"fixed_image\"][0][0], check_data[\"fixed_label\"][0][0])\n",
    "moving_image, moving_label = (check_data[\"moving_image\"][0][0], check_data[\"moving_label\"][0][0])\n",
    "print(f\"image shape: {fixed_image.shape}, label shape: {fixed_label.shape}\")\n",
    "# plot the slice [:, :, 80]\n",
    "plt.figure(\"check\", (12, 6))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title(\"moving_image\")\n",
    "plt.imshow(moving_image[:, :, 80], cmap=\"gray\")\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title(\"moving_label\")\n",
    "plt.imshow(moving_label[:, :, 80])\n",
    "plt.show()\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title(\"fixed_image\")\n",
    "plt.imshow(fixed_image[:, :, 80], cmap=\"gray\")\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title(\"fixed_label\")\n",
    "plt.imshow(fixed_label[:, :, 80])\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define CacheDataset and DataLoader for training and validation\n",
    "\n",
    "Here we use CacheDataset to accelerate training and validation process, it's 10x faster than the regular Dataset.\n",
    "To achieve best performance, set cache_rate=1.0 to cache all the data, if memory is not enough, set lower value.\n",
    "Users can also set cache_num instead of cache_rate, will use the minimum value of the 2 settings.\n",
    "And set num_workers to enable multi-threads during caching.\n",
    "If want to to try the regular Dataset, just change to use the commented code below.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:03<00:00,  5.49it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=4)\n",
    "# train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld\n",
    "# to generate 2 x 4 images for network training\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=4)\n",
    "\n",
    "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=0)\n",
    "# val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=2, num_workers=4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Model, Loss, Optimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# standard PyTorch program style: create UNet, DiceLoss and Adam optimizer\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = LocalNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=2,\n",
    "        out_channels=3,\n",
    "        num_channel_initial=32,\n",
    "        extract_levels=[0, 1, 2, 3],\n",
    "        out_activation=None,\n",
    "        out_initializer=\"zeros\").to(device)\n",
    "warp_layer = Warp(spatial_dims=3).to(device)\n",
    "image_loss = MSELoss()\n",
    "label_loss = DiceLoss()\n",
    "regularization = BendingEnergyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define a forward pass function for ddf computation and warping to avoid duplicate coding."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def forward(batch_data, model):\n",
    "    fixed_image = batch_data[\"fixed_image\"].to(device)\n",
    "    moving_image = batch_data[\"moving_image\"].to(device)\n",
    "    moving_label = batch_data[\"moving_label\"].to(device)\n",
    "    ddf = model(torch.cat((moving_image, fixed_image), dim=1))\n",
    "    pred_image = warp_layer(moving_image, ddf)\n",
    "    pred_label = warp_layer(moving_label, ddf)\n",
    "    return ddf, pred_image, pred_label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Execute a typical PyTorch training process"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 1\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ddf, pred_image, pred_label = forward(batch_data, model)\n",
    "\n",
    "        fixed_image = batch_data[\"fixed_image\"].to(device)\n",
    "        fixed_label = batch_data[\"fixed_label\"].to(device)\n",
    "        loss = image_loss(pred_image, fixed_image) + label_loss(pred_label, fixed_label) + regularization(ddf)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
    "    \n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            metric_sum = 0.0\n",
    "            metric_count = 0\n",
    "            for val_data in val_loader:\n",
    "\n",
    "                val_ddf, val_pred_image, val_pred_label = forward(val_data, model)\n",
    "\n",
    "                val_fixed_image = val_data[\"fixed_image\"].to(device)\n",
    "                val_fixed_label = val_data[\"fixed_label\"].to(device)\n",
    "                value = compute_meandice(\n",
    "                    y_pred=val_pred_label,\n",
    "                    y=val_fixed_label,\n",
    "                    include_background=False,\n",
    "                )\n",
    "                metric_count += len(value)\n",
    "                metric_sum += value.sum().item()\n",
    "            metric = metric_sum / metric_count\n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), os.path.join(root_dir, \"best_metric_model.pth\"))\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                f\"\\nbest mean dice: {best_metric:.4f} at epoch: {best_metric_epoch}\"\n",
    "            )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"train completed, best_metric: {best_metric:.4f}  at epoch: {best_metric_epoch}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plot the loss and metric"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val Mean Dice\")\n",
    "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Check best model output with the input image and label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\")))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, val_data in enumerate(val_loader):\n",
    "        val_ddf, val_pred_image, val_pred_label = forward(val_data, model)\n",
    "\n",
    "        # plot the slice [:, :, 80]\n",
    "        plt.figure(\"check\", (18, 6))\n",
    "        plt.subplot(1, 6, 1)\n",
    "        plt.title(f\"moving_image {i}\")\n",
    "        plt.imshow(val_data[\"moving_image\"][0, 0, :, :, 80], cmap=\"gray\")\n",
    "        plt.subplot(1, 6, 2)\n",
    "        plt.title(f\"moving_label {i}\")\n",
    "        plt.imshow(val_data[\"moving_label\"][0, 0, :, :, 80])\n",
    "        plt.subplot(1, 6, 3)\n",
    "        plt.title(f\"fixed_image {i}\")\n",
    "        plt.imshow(val_data[\"fixed_image\"][0, 0, :, :, 80], cmap=\"gray\")\n",
    "        plt.subplot(1, 6, 4)\n",
    "        plt.title(f\"fixed_label {i}\")\n",
    "        plt.imshow(val_data[\"fixed_label\"][0, 0, :, :, 80])\n",
    "        plt.subplot(1, 6, 5)\n",
    "        plt.title(f\"pred_image {i}\")\n",
    "        plt.imshow(val_pred_image[0, 0, :, :, 80], cmap=\"gray\")\n",
    "        plt.subplot(1, 6, 6)\n",
    "        plt.title(f\"pred_label {i}\")\n",
    "        plt.imshow(val_pred_label[0, 0, :, :, 80])\n",
    "        plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cleanup data directory\n",
    "\n",
    "Remove directory if a temporary was used."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if directory is None:\n",
    "    shutil.rmtree(root_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}